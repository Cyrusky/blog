---
title: 朴素贝叶斯分类器
tags:
  - 机器学习
categories:
  - AI
  - Machine Learning
toc: true
abbrlink: fb4c2b27
date: 2019-10-25T21:30:51.000Z
cover: /assets/images/20191029093208.webp
thumbnail: /assets/thumbnail/20191029093208.webp
---

# 贝叶斯判定准则

贝叶斯判定该准则被描述为：为了最小化总体风险，只需要在每个样本上选择那个能使条件风险$R(c|x)$最小的类别标记，即：

$$
h^\star (x) = \arg\min_{c \in \mathcal{Y}} R(c | x)
\tag{1}
$$

此时，$h^\star$称作贝叶斯最优分类器。

> 注：此时的$h^\star$并不是一个可以计算的值，只是一个贝叶斯最优分类器的理论指导。

<!-- more -->

> $\arg$ 是变元（即自变量argument）的英文缩写
> $\arg \min$ 就是使后面这个式子达到最小值时的变量的取值
> $\arg \max$ 就是使后面这个式子达到最大值时的变量的取值
>
> 例如 函数$F(x,y)$:
>
> > $\arg \min F(x,y)$就是指当$F(x,y)$取得最小值时，变量$x,y$的取值
> > $\arg\max F(x,y)$就是指当$F(x,y)$取得最大值时，变量$x,y$的取值

已知,条件风险$R(c|x)$的计算公式为：

$$
R(c|x) = \sum_{j=1}^N \lambda_{ij}P(c_j|x)
\tag{2,7.1}
$$

其中：

$$
\lambda_{ij} = \left \lbrace
\begin{matrix}
0, \quad if \quad i=j \\\\
1, \quad otherwise
\end{matrix}
\right .
\tag{3,7.4}
$$

将上面的式子代入$(2)$式，则会消去所有判定不正确（即$i \ne j$）的项（值），就得到下面你的式子：

$$
R(c|x) = \sum_{j=1,i=j}^N \lambda_{ij}P(c_j|x)
\tag{4}
$$

由于：

$$
\sum_{i=1}^N P(c_j|x) = 1
\tag{5}
$$

所以：

$$
R(c|x) = 1 - \sum_{j=1,i\ne j}^N \lambda_{ij}P(c_j|x) = 1 - P(c|x)
\tag{5,7.5}
$$

此时，贝叶斯最优分类器可以以下面的形式表示：

$$
h^\star = \arg \max_{c \in \mathcal{Y}} P(c|x)
\tag{6,7.6}
$$

此时的直观意思就是，将原来贝叶斯最优分类器中求取最小化条件风险的问题，转换为等价的求最大化后验概率的问题了。

# 多元正态分布参数的极大似然估计

> 一元正态分布参数的极大似然估计： Todo

一直对数似然函数为：

$$
LL(\theta_c) = \sum_{x \in D_c} \log P(x|\theta_c)
\tag{7,7.10}
$$

> 注：
>
> 1. 取对数的原因，一方面是因为要求导，所以取对数方便，另一方面是因为似然函数在后续的计算中需要进行连乘操作，在计算机中计算时，容易造成下溢（个人理解就是，小到计算机无法表示了）
>
> 2. 因为对数函数是一个单调递增的函数，所以，对数函数的自变量的最值和函数值的最值会在统一的地方取到，这是对数函数可以代替原$LL$函数的原因。
>
> 3. 因为所有的对数函数都是单调递增的，所以对数的底数没关系，只需要单调递增就可以了，所以$(7)$式可以写为：
     >
     >    $$
     > LL(\theta_c) = \sum_{x \in D_c} \ln P(x|\theta_c)
     > \tag{7'}
     > $$

由于，$P(x|\theta_c) = P(x|c) \sim \mathcal{N}(\mu_c, \sigma^2_c)$，那么：

$$
P(x|\theta_c) = \frac{1}{\sqrt{(2\pi)^d| \Sigma_c |}}\bullet
\exp{\left [ -\frac{1}{2} (x - \mu_c)^T \Sigma_c^{-1} (x - \mu_c) \right ]}
\tag{8}
$$

其中， $d$表示$x$的维数，即$x$有多少个特征，$\Sigma_c = \sigma_c^2 $为对称正定协方差矩阵，
$|\Sigma_c|$表示$\Sigma_c$的行列式，将上式代入对数似然函数，可得：

$$
\begin{align}
LL(\theta_c) & = \sum_{x \in D_c} \ln \left [ \frac{1}{\sqrt{(2\pi)^d |\Sigma_c|}} \exp
\left [ -\frac{1}{2} (x - \mu_c)^T \Sigma_c^{-1}(x-\mu_c) \right ] \right ] \\\\
& = \sum_{i = 1}^N \ln \left [ \frac{1}{\sqrt{(2\pi)^d |\Sigma_c|}} \exp
\left [ -\frac{1}{2} (x_i - \mu_c)^T \Sigma_c^{-1}(x_i-\mu_c) \right ] \right ] \\\\
& = \sum_{i = 1}^N \left \lbrace \ln \frac{1}{\sqrt{(2\pi)^d }} + \ln \frac{1}{\sqrt{|\Sigma_c|}} + \ln \left [  \exp
\left [ -\frac{1}{2} (x_i - \mu_c)^T \Sigma_c^{-1}(x_i-\mu_c) \right ] \right ] \right \rbrace \\\\
& = \sum_{i = 1}^N
\left [  \ln \frac{1}{\sqrt{(2\pi)^d }} + \ln \frac{1}{\sqrt{|\Sigma_c|}} -\frac{1}{2} (x_i - \mu_c)^T \Sigma_c^{-1}(x_i-\mu_c) \right ] \\\\
& = \frac{Nd}{2} \ln (2\pi) - \frac{N}{2} \ln |\Sigma_c| - \frac{1}{2} \sum_{i = 1}^N  (x_i - \mu_c)^T \Sigma_c^{-1}(
x_i-\mu_c)  \\\\
\end{align} \\
\mathcal{Y}
\tag{9}
$$

由于参数$\theta_c$的极大似然估计$\hat{\theta}_c$为：

$$
\hat{\theta}\_c = \arg \max\_{\theta\_c} LL(\theta\_c)
\tag{10,7.11}
$$

对数似然函数$LL(\theta_c)$分别对参数$\mu_c$ 和 $\sigma_c$求偏导，如下：

$$
\frac{\partial LL(\theta_c)}{\partial \mu_c} = \sum_{i=1}^N \Sigma_c^{-1}x_i - N\Sigma_c^{-1} \mu_c \\\\
\frac{\partial LL(\theta_c)}{\partial \Sigma_c} = -\frac{N}{2} \Sigma_c^{-1} + \frac{1}{2} \sum_{i=1}^N
\left [ \Sigma_c^{-1}(x_i - \mu_c)(x_i-\mu)^T\Sigma_c^{-1} \right ]
\tag{11}
$$

令两个一节偏导数为0，则可得出：

$$
\hat{\mu}\_c = \frac{1}{|D\_c|} \sum\_{x \in D\_c} x , \\\\
\hat{\sigma}\_c^2 = \frac{1}{|D\_c|} \sum\_{x \in D\_c} (x - \hat{\mu}\_c)(x - \hat{\mu}\_c)^T.
\tag{12,7.13}
$$

> 以上求解中使用了两个技巧：
>
> 1. $\Sigma$是对称的，所以$\Sigma^T = \Sigma$
> 2. $(AB)T = B^TA^T$; $(AB)^{-1} = ^{-1}B^{-1}$

# 朴素贝叶斯分类器

已知最小化分类错误率的贝叶斯最有分类器为:

$$
h^\star = \arg \min_{c \in \mathcal{Y}} P (c | x) = \arg \min_{c \in \mathcal{Y}} \frac{P(c)P(x|c)}{P(x)}
\tag{13,7.14}
$$

根据属性条件独立性假设:

$$
h^\star = \arg \min_{c \in \mathcal{Y}} P (c) \prod_{i=1}^d P(x_i | c) \tag{14, 7.15}
$$

> 独立事件的联合概率为其乘积,牺牲了准确性,简化了计算.

其先验概率根据大数定律为:

$$
P(c) = \frac{|D_c|}{|D|} \tag{15,7.16}
$$

对于其条件概率(似然值)来说,又分为离散属性和连续属性:

离散属性:

$$
P(x_i | c) = \frac{|D_{c,x_i}|}{|D_c|}
\tag{16,7.17}
$$

连续属性：

$$
P(x_i | c) = \frac{1}{\sqrt{2 \pi} \sigma_{c,i}} \exp \left ( - \frac{(x_i - \mu_{c,i})^2}{2\sigma^2_{c,i}} \right )
\tag{17,7.18}
$$
