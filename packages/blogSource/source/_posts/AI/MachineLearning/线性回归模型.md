---
title: 机器学习之线性回归模型
tags:
  - 数学
categories:
  - AI
  - Machine Learning
toc: true
cover: /assets/images/20190926204917.webp
graphic: true
abbrlink: 61e41abb
date: 2019-09-25T10:58:32.000Z
thumbnail: /assets/thumbnail/20190926204917.webp
---

# 高斯分布

## 高斯分布的概率密度函数

$$
f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^ {-\frac{(x-\mu)^2}{2 \sigma^2}}
\tag{1}
$$

<!-- more -->

记做：
$$
X \sim N(\mu , \sigma ^ 2)
\tag{2}
$$
其函数图像为：

<div class="bk-root"id="255c804b-c9f6-4cdf-9ef9-e3ba226437b6"data-root-id="1043"></div><script type="application/json"id="1125">{"398620e6-108f-4f46-89fb-af52bfa27cbd":{"roots":{"references":[{"attributes":{"callback":null,"end":0.4,"start":-0.1},"id":"1005","type":"Range1d"},{"attributes":{"callback":{"id":"1039","type":"CustomJS"},"end":10,"start":0.1,"step":0.1,"title":"\u6807\u51c6\u5dee(\u03c3)","value":3},"id":"1040","type":"Slider"},{"attributes":{"children":[{"id":"1002","subtype":"Figure","type":"Plot"},{"id":"1042","type":"WidgetBox"}]},"id":"1043","type":"Row"},{"attributes":{"line_alpha":0.1,"line_color":"#1f77b4","line_width":3,"x":{"field":"x"},"y":{"field":"y"}},"id":"1036","type":"Line"},{"attributes":{},"id":"1017","type":"BasicTicker"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1021","type":"PanTool"},{"id":"1022","type":"WheelZoomTool"},{"id":"1023","type":"BoxZoomTool"},{"id":"1024","type":"SaveTool"},{"id":"1025","type":"ResetTool"},{"id":"1026","type":"HelpTool"}]},"id":"1027","type":"Toolbar"},{"attributes":{"callback":{"id":"1039","type":"CustomJS"},"end":3,"start":-3,"step":0.1,"title":"\u671f\u671b(\u03bc)","value":0},"id":"1041","type":"Slider"},{"attributes":{},"id":"1021","type":"PanTool"},{"attributes":{"args":{"mu":{"id":"1041","type":"Slider"},"sigma":{"id":"1040","type":"Slider"},"source":{"id":"1001","type":"ColumnDataSource"}},"code":"var data = source.data;var mu = mu.value;var sigma = sigma.value;x = data['x'];y = data['y'];console.log(123);for (i = 0; i &lt; x.length; i++) {y[i] = (1 / (sigma * Math.sqrt(2 * Math.PI))) * Math.exp(- (Math.pow(x[i] - mu, 2) / (2 * sigma * sigma)));}source.change.emit();"},"id":"1039","type":"CustomJS"},{"attributes":{"text":""},"id":"1045","type":"Title"},{"attributes":{"below":[{"id":"1011","type":"LinearAxis"}],"center":[{"id":"1015","type":"Grid"},{"id":"1020","type":"Grid"}],"left":[{"id":"1016","type":"LinearAxis"}],"plot_height":400,"plot_width":400,"renderers":[{"id":"1037","type":"GlyphRenderer"}],"title":{"id":"1045","type":"Title"},"toolbar":{"id":"1027","type":"Toolbar"},"x_range":{"id":"1003","type":"Range1d"},"x_scale":{"id":"1007","type":"LinearScale"},"y_range":{"id":"1005","type":"Range1d"},"y_scale":{"id":"1009","type":"LinearScale"}},"id":"1002","subtype":"Figure","type":"Plot"},{"attributes":{},"id":"1022","type":"WheelZoomTool"},{"attributes":{"ticker":{"id":"1012","type":"BasicTicker"}},"id":"1015","type":"Grid"},{"attributes":{"overlay":{"id":"1052","type":"BoxAnnotation"}},"id":"1023","type":"BoxZoomTool"},{"attributes":{},"id":"1047","type":"BasicTickFormatter"},{"attributes":{"line_alpha":0.6,"line_color":"#1f77b4","line_width":3,"x":{"field":"x"},"y":{"field":"y"}},"id":"1035","type":"Line"},{"attributes":{"callback":null,"data":{"x":{"__ndarray__":"AAAAAAAAFMBDYt7OkJgTwIbEvJ0hMRPAyiabbLLJEsANiXk7Q2ISwFDrVwrU+hHAk0022WSTEcDXrxSo9SsRwBoS83aGxBDAXXTRRRddEMBArV8pUOsPwMdxHMdxHA/ATjbZZJNNDsDU+pUCtX4NwFq/UqDWrwzA4YMPPvjgC8BoSMzbGRILwO4MiXk7QwrAdNFFF110CcD7lQK1fqUIwIFav1Kg1gfACB988MEHB8CO4ziO4zgGwBWo9SsFagXAm2yyySabBMAiMW9nSMwDwKj1KwVq/QLAL7rooosuAsC1fqVArV8BwDxDYt7OkADAhA8++OCD/7+SmLczJOb9v54hMW9nSPy/qqqqqqqq+r+4MyTm7Qz5v8S8nSExb/e/0kUXXXTR9b/ezpCYtzP0v+xXCtT6lfK/+OCDDz748L8I1PqVArXuvyjm7QyJeeu/QPjggw8+6L9YCtT6lQLlv3Acx3Ecx+G/IF100UUX3b9QgVq/UqDWv4ClQK1fKdC/YJNNNtlkw78Ab2dIzNupvwBvZ0jM26k/YJNNNtlkwz+ApUCtXynQP1CBWr9SoNY/EF100UUX3T9wHMdxHMfhP1gK1PqVAuU/QPjggw8+6D8g5u0MiXnrPwjU+pUCte4/+OCDDz748D/sVwrU+pXyP9zOkJi3M/Q/0EUXXXTR9T/EvJ0hMW/3P7gzJObtDPk/rKqqqqqq+j+cITFvZ0j8P5CYtzMk5v0/hA8++OCD/z88Q2LezpAAQLR+pUCtXwFALrrooosuAkCo9SsFav0CQCIxb2dIzANAmmyyySabBEAUqPUrBWoFQI7jOI7jOAZACB988MEHB0CAWr9SoNYHQPyVArV+pQhAdNFFF110CUDsDIl5O0MKQGhIzNsZEgtA4IMPPvjgC0Bcv1Kg1q8MQNT6lQK1fg1ATDbZZJNNDkDIcRzHcRwPQECtXylQ6w9AXHTRRRddEEAaEvN2hsQQQNavFKj1KxFAlE022WSTEUBQ61cK1PoRQAyJeTtDYhJAyiabbLLJEkCGxLydITETQERi3s6QmBNAAAAAAAAAFEA=","dtype":"float64","shape":[100]},"y":{"__ndarray__":"bQKL9jj6oD+LZgaCfPKhP8wMhK1t86I/h8j9fe/8oz8miwO22w6lP6ysnIECKaY/wpPhKypLpz9rslffDnWoPxZ4EXJipqk//LCIPszeqj+pxhsK6R2sP2R1BfpKY60/Z9iSl3murj9HPEXk8f6vP1MHOj8TqrA/WdRz679WsT964eM7LgWyP6cpjK4ItbI/ANRuL/Vlsz8ZhW5WlRe0Px4v5a2GybQ/pbbGAWN7tT9vjhG3wCy2P3EbPCsz3bY/63U6G0uMtz+uJ6URlzm4P2cQd9uj5Lg/T9LGAv2MuT8wSs9OLTK6P6rOiki/07o/rncWwz1xuz/DrQVnNAq8Pwjmwj8wnrw//uMQSsAsvT/6QLgCdrW9P+9xZ/TlN74/FSnIQ6izvj841cs4WSi/P30yMsSZlb8/L2dQABD7vz+pgRLWMyzAP62y5k+pVsA/77m9nMR8wD8ynAthZZ7AP8pLY+Ruu8A/VQNTOsjTwD/ixgdmXOfAP6W7cHga9sA/psWlqPX/wD/rNmBm5QTBP+s2YGblBME/psWlqPX/wD+lu3B4GvbAP+LGB2Zc58A/VQNTOsjTwD/KS2PkbrvAPzKcC2FlnsA/77m9nMR8wD+usuZPqVbAP6mBEtYzLMA/L2dQABD7vz99MjLEmZW/PznVyzhZKL8/FSnIQ6izvj/vcWf05Te+P/pAuAJ2tb0//uMQSsAsvT8I5sI/MJ68P8OtBWc0Crw/rncWwz1xuz+qzopIv9O6PzBKz04tMro/UNLGAv2MuT9nEHfbo+S4P64npRGXObg/7HU6G0uMtz9yGzwrM922P2+OEbfALLY/pbbGAWN7tT8fL+Wthsm0PxaFblaVF7Q/ANRuL/Vlsz+oKYyuCLWyP3rh4zsuBbI/WtRz679WsT9RBzo/E6qwP0c8ReTx/q8/bNiSl3murj9idQX6SmOtP6nGGwrpHaw//rCIPszeqj8WeBFyYqapP26yV98Odag/vpPhKypLpz+srJyBAimmPymLA7bbDqU/h8j9fe/8oz/MDIStbfOiP4lmBoJ88qE/bQKL9jj6oD8=","dtype":"float64","shape":[100]}},"selected":{"id":"1050","type":"Selection"},"selection_policy":{"id":"1051","type":"UnionRenderers"}},"id":"1001","type":"ColumnDataSource"},{"attributes":{},"id":"1050","type":"Selection"},{"attributes":{"formatter":{"id":"1049","type":"BasicTickFormatter"},"ticker":{"id":"1012","type":"BasicTicker"}},"id":"1011","type":"LinearAxis"},{"attributes":{},"id":"1024","type":"SaveTool"},{"attributes":{},"id":"1007","type":"LinearScale"},{"attributes":{},"id":"1025","type":"ResetTool"},{"attributes":{},"id":"1012","type":"BasicTicker"},{"attributes":{},"id":"1049","type":"BasicTickFormatter"},{"attributes":{"callback":null,"end":5,"start":-5},"id":"1003","type":"Range1d"},{"attributes":{},"id":"1051","type":"UnionRenderers"},{"attributes":{},"id":"1026","type":"HelpTool"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1052","type":"BoxAnnotation"},{"attributes":{"data_source":{"id":"1001","type":"ColumnDataSource"},"glyph":{"id":"1035","type":"Line"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1036","type":"Line"},"selection_glyph":null,"view":{"id":"1038","type":"CDSView"}},"id":"1037","type":"GlyphRenderer"},{"attributes":{"source":{"id":"1001","type":"ColumnDataSource"}},"id":"1038","type":"CDSView"},{"attributes":{"children":[{"id":"1040","type":"Slider"},{"id":"1041","type":"Slider"}]},"id":"1042","type":"WidgetBox"},{"attributes":{},"id":"1009","type":"LinearScale"},{"attributes":{"formatter":{"id":"1047","type":"BasicTickFormatter"},"ticker":{"id":"1017","type":"BasicTicker"}},"id":"1016","type":"LinearAxis"},{"attributes":{"dimension":1,"ticker":{"id":"1017","type":"BasicTicker"}},"id":"1020","type":"Grid"}],"root_ids":["1043"]},"title":"Bokeh Application","version":"1.3.4"}}</script><script type="text/javascript">(function(){var fn=function(){Bokeh.safely(function(){(function(root){function embed_document(root){var docs_json=document.getElementById('1125').textContent;var render_items=[{"docid":"398620e6-108f-4f46-89fb-af52bfa27cbd","roots":{"1043":"255c804b-c9f6-4cdf-9ef9-e3ba226437b6"}}];root.Bokeh.embed.embed_items(docs_json,render_items)}if(root.Bokeh!==undefined){embed_document(root)}else{var attempts=0;var timer=setInterval(function(root){if(root.Bokeh!==undefined){embed_document(root);clearInterval(timer)}attempts++;if(attempts>100){console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");clearInterval(timer)}},10,root)}})(window)})};if(document.readyState!="loading")fn();else document.addEventListener("DOMContentLoaded",fn)})();</script>
可以看出，正态分布的数学期望值或期望值$\mu$等于位置参数，决定了分布的位置；其方差$\sigma^2$的开平方或这说标准差$\sigma$（标准差的平方等于方差）等于尺度参数，决定了分布的幅度。

## 以上图像的Python代码

```python
import numpy as np
from bokeh.layouts import row, widgetbox
from bokeh.models import CustomJS, Slider
from bokeh.plotting import figure, output_file, show, ColumnDataSource

N = 100
x = np.linspace(-5.0, 5.0, N)
mu = 0
sigma = 3
s = (1 / (sigma * np.sqrt(2 * np.pi))) \
    * np.exp(- (np.power(x - mu, 2) / (2 * sigma ** 2)))
source = ColumnDataSource(data=dict(x=x, y=s))
plot = figure(y_range=(-0.1, 0.4), x_range=(-5, 5), plot_width=400, plot_height=400)
plot.line('x', 'y', source=source, line_width=3, line_alpha=0.6)
callback = CustomJS(args=dict(source=source),
                    code="var data = source.data;"
                         "var mu = mu.value;"
                         "var sigma = sigma.value;"
                         "x = data['x'];"
                         "y = data['y'];"
                         "console.log(123);"
                         "for (i = 0; i < x.length; i++) {"
                         "y[i] = (1 / (sigma * Math.sqrt(2 * Math.PI))) * Math.exp(- "
                         "(Math.pow(x[i] - mu, 2) / (2 * sigma * sigma)));"
                         "}"
                         "source.change.emit();")
sigma_slider = Slider(start=0.1, end=10, value=3, step=.1,
                      title="标准差(σ)", callback=callback)
callback.args["sigma"] = sigma_slider

mu_slider = Slider(start=-3, end=3, value=0, step=.1,
                   title="期望(μ)", callback=callback)
callback.args["mu"] = mu_slider
layout = row(
    plot,
    widgetbox(sigma_slider, mu_slider),
)
output_file("../output/html/04/slider.html", title="正态分布概率密度函数")
show(layout)
```

## 二维高斯分布概率密度函数

$$
f(x,y) = \left ( 2 \pi \sigma_1\sigma_2 \sqrt{1-\rho^2} \right)^{-1}
\exp{\left \lbrace - \frac{1}{2(1-\rho^2)}
\left [  \frac{(x - \mu_1)^2}{\sigma_1^2} - \frac{2\rho(x-\mu_1)(x-\mu_2)}{\sigma_1 \sigma_2} + \frac{(x - \mu_2)^2}{\sigma_2^2} \right]
\right \rbrace }
\tag{3}
$$

其中$\mu_1,\mu_2,\sigma_1,\sigma_2,\rho$都是常数，$x$是自变量，我们称作$X_1,X_2$服从参数为$\mu_1,\mu_2,\sigma_1,\sigma_2,\rho$的二维正态分布，常把这个分布记作：
$$
(X_1,X_2) \sim N(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,\rho)\tag{4}
$$
的范围分别为：
$$
\begin{align}
\\\\ - \infty \lt & \mu_1 \lt + \infty
\\\\ - \infty \lt & \mu_2 \lt + \infty
\\\\ -1 \lt & \rho \lt 1
\\\\ \sigma_1 & \ge 0  
\\\\ \sigma_2 & \ge 0
\end{align} \tag{4.1}
$$
其函数图像为：

![标准二维正态分布图像](/assets/images/20190925214942.webp)

# 最大似然估计(MLE)

![https://blog.csdn.net/zengxiantao1994/article/details/72787849](/assets/images/20190925215322.webp)

> 注：最大似然估计在我看来就是，将在先验经验中出现的最多的分类结果作为分类依据。
>
> 比如说，有十张照片，都是狗狗，这个是先验经验，我们从中抽取出一种特征：两个眼睛，与之关联起来之后，我们可以说：两个眼睛~狗
>
> 但是在继续训练的时候，我们发现，猫也有两个眼睛，这会造成分类错误，所以添加更多的特征，比如：会汪汪叫。结果，发现这个正确概率率提高了不少，除了少数误差数据，比如鹦鹉学舌、人声之类的。我们几乎可以肯定（两个眼睛,
> 汪汪叫）~ 狗。
>
> 注：正确理解正确率的含义，就是正确的概率。

原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。

## 数学表述

由于样本集中的样本都是独立同分布，可以只考虑一类样本集$D$，来估计参数向量$\theta$。记已知的样本集为：
$$
D = \lbrace x_1, x_2, \dots, x_N \rbrace
\tag{5}
$$
似然函数（$linkehood \quad function$）：联合概率密度函数$p(D|\theta)$称为相对于$\lbrace x_1, x_2, \dots, x_N
\rbrace$的$\theta$的似然函数。
$$
l(\theta) = p(D| \theta) = p(x_1,x_2,\dots,x_N) = \prod_{i=1}^N p(D|\theta)
\tag{5}
$$
如果$\hat{\theta}$是参数空间中能使似然函数$l(\theta)$最大的θ值，则$\hat{\theta}$应该是**“最可能”**
的参数值，那么$\hat{\theta}$就是$\theta$的极大似然估计量。它是样本集的函数，记作：
$$
\hat{\theta} = d(x_1,x_2,\dots, x_N)=d(D)
\tag{6}
$$
其中，$\theta(x_1,x_2,\dots, x_N)$称作极（最）大似然估计函数的估计值。

# 最小二乘法

> 以下来自维基百科

某次实验得到了四个数据点:$ (1,6),(2,5),(3,7),(4,10)$。我们希望找出一条和这四个点最匹配的直线$y=\theta_1 + \theta_2
x$，即找出在某种“最佳情况”下能够大致符合如下超定线性方程组的$\beta_1$和$\beta_2$：

应为有四组数据，我们可以将方程组表达为：
$$
y = \theta_0x_0 + \theta_1 x _1 \\\\
\tag{7.1}
$$

$$
y = \theta x
\tag{7.2}
$$

$7.2$是$7.1$的向量表示方法。

在例子中，我们的方程组为：
$$
\begin{align}
x_1 + x_2 & = 6 \\\\
x_1 + 2x_2 & = 5 \\\\
x_1 + 3x_2 & = 6 \\\\
x_1 + 4x_2 & = 10 \\\\
\end{align}
\tag{8}
$$
表达为向量：
$$
\left [
\begin{matrix}
1 & 1 \\\\
1 & 2 \\\\
1 & 3 \\\\
1 & 4
\end{matrix}
\right] \left [
\begin{matrix}
x_1 \\\\
x_2
\end{matrix}
\right ] = \left[
\begin{matrix}
6 \\\\
5 \\\\
7 \\\\
10
\end{matrix}
\right]
\tag{9}
$$
最小二乘法采用的手段是尽量使得等号两边的方差最小，也就是找出下面这个函数的最小值：
$$
S(\beta_1, \beta_2) = [6-(\beta_1 + \beta_2)]^2 + [5-(\beta_1 + 2\beta_2)]^2 +
[7-(\beta_1 + 3\beta_2)]^2 + [10-(\beta_1 + 4\beta_2)]^2 \tag{10}
$$
> 对于我们的拟合曲线来说，上面的方差函数就是我们所说的损失函数的一种。其中的每一项，如$6-(\beta_1+\beta_2)
> $就是其偏差。为防止正负偏差互相抵消，所以对其进行平方操作，然后求所有偏差之和的最小值，就是拟合最好的情况，

对两边分别求两个参数的偏导数：
$$
\frac{\partial S }{\partial\beta_1} = 0 = 8\beta_1 + 20 \beta_2 + 56 \\\\
\frac{\partial S}{\partial \beta_2} = 0 = 20\beta_1 + 60\beta_2 + 154
\tag{11}
$$
求解方程组，得到：
$$
\beta_1 = 3.5 \\\\
\beta_2 = 1.4
\tag{12}
$$
如此就得到了一个只有两个未知数的方程组，很容易就可以解出：根据结论。最小值可以通过对$S(\beta_1, \beta_2)
$分别求$\beta_1$和$\beta_2$的偏导数偏导数)，然后使它们等于零得到。

![图片来自维基百科](/assets/images/20190926083344.webp)

也就是说直线$y=3.5 + 1.4 x$ 是最佳的。

# $Logistic$回归

## $Sigmoid$函数

<div class="bk-root"id="65c3b379-fc29-489d-aa67-abbad1fcf97f"data-root-id="1002"></div><script type="application/json"id="1128">{"7344412d-7bc9-4a59-8502-cdd13ad92044":{"roots":{"references":[{"attributes":{"dimension":"height","line_color":{"value":"gray"},"line_dash":[6],"location":0},"id":"1044","type":"Span"},{"attributes":{"line_color":{"value":"gray"},"line_dash":[6],"location":0},"id":"1046","type":"Span"},{"attributes":{"data_source":{"id":"1001","type":"ColumnDataSource"},"glyph":{"id":"1040","type":"Line"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1041","type":"Line"},"selection_glyph":null,"view":{"id":"1043","type":"CDSView"}},"id":"1042","type":"GlyphRenderer"},{"attributes":{},"id":"1052","type":"BasicTickFormatter"},{"attributes":{},"id":"1017","type":"BasicTicker"},{"attributes":{"source":{"id":"1001","type":"ColumnDataSource"}},"id":"1043","type":"CDSView"},{"attributes":{},"id":"1022","type":"WheelZoomTool"},{"attributes":{},"id":"1009","type":"LinearScale"},{"attributes":{"ticker":{"id":"1012","type":"BasicTicker"}},"id":"1015","type":"Grid"},{"attributes":{"formatter":{"id":"1052","type":"BasicTickFormatter"},"ticker":{"id":"1012","type":"BasicTicker"}},"id":"1011","type":"LinearAxis"},{"attributes":{},"id":"1053","type":"UnionRenderers"},{"attributes":{},"id":"1054","type":"Selection"},{"attributes":{},"id":"1012","type":"BasicTicker"},{"attributes":{"dimension":1,"ticker":{"id":"1017","type":"BasicTicker"}},"id":"1020","type":"Grid"},{"attributes":{"callback":null,"end":5,"start":-5},"id":"1003","type":"Range1d"},{"attributes":{"callback":null,"end":1.1,"start":-0.1},"id":"1005","type":"Range1d"},{"attributes":{"callback":null,"data":{"x":{"__ndarray__":"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","dtype":"float64","shape":[200]},"y":{"__ndarray__":"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","dtype":"float64","shape":[200]}},"selected":{"id":"1054","type":"Selection"},"selection_policy":{"id":"1053","type":"UnionRenderers"}},"id":"1001","type":"ColumnDataSource"},{"attributes":{"overlay":{"id":"1055","type":"BoxAnnotation"}},"id":"1023","type":"BoxZoomTool"},{"attributes":{},"id":"1007","type":"LinearScale"},{"attributes":{},"id":"1024","type":"SaveTool"},{"attributes":{"line_alpha":0.1,"line_color":"#1f77b4","line_width":3,"x":{"field":"x"},"y":{"field":"y"}},"id":"1036","type":"Line"},{"attributes":{"formatter":{"id":"1050","type":"BasicTickFormatter"},"ticker":{"id":"1017","type":"BasicTicker"}},"id":"1016","type":"LinearAxis"},{"attributes":{},"id":"1025","type":"ResetTool"},{"attributes":{"text":""},"id":"1047","type":"Title"},{"attributes":{"source":{"id":"1001","type":"ColumnDataSource"}},"id":"1038","type":"CDSView"},{"attributes":{"line_alpha":0.1,"line_color":"#1f77b4","line_width":3,"x":{"field":"x"},"y":{"field":"y"}},"id":"1041","type":"Line"},{"attributes":{"line_color":{"value":"gray"},"line_dash":[6],"location":1},"id":"1045","type":"Span"},{"attributes":{},"id":"1050","type":"BasicTickFormatter"},{"attributes":{},"id":"1026","type":"HelpTool"},{"attributes":{},"id":"1021","type":"PanTool"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1055","type":"BoxAnnotation"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1021","type":"PanTool"},{"id":"1022","type":"WheelZoomTool"},{"id":"1023","type":"BoxZoomTool"},{"id":"1024","type":"SaveTool"},{"id":"1025","type":"ResetTool"},{"id":"1026","type":"HelpTool"}]},"id":"1027","type":"Toolbar"},{"attributes":{"below":[{"id":"1011","type":"LinearAxis"}],"center":[{"id":"1015","type":"Grid"},{"id":"1020","type":"Grid"}],"left":[{"id":"1016","type":"LinearAxis"}],"plot_height":400,"renderers":[{"id":"1037","type":"GlyphRenderer"},{"id":"1042","type":"GlyphRenderer"},{"id":"1044","type":"Span"},{"id":"1046","type":"Span"},{"id":"1045","type":"Span"}],"title":{"id":"1047","type":"Title"},"toolbar":{"id":"1027","type":"Toolbar"},"x_range":{"id":"1003","type":"Range1d"},"x_scale":{"id":"1007","type":"LinearScale"},"y_range":{"id":"1005","type":"Range1d"},"y_scale":{"id":"1009","type":"LinearScale"}},"id":"1002","subtype":"Figure","type":"Plot"},{"attributes":{"line_alpha":0.6,"line_color":"#1f77b4","line_width":3,"x":{"field":"x"},"y":{"field":"y"}},"id":"1035","type":"Line"},{"attributes":{"line_alpha":0.6,"line_color":"#1f77b4","line_width":3,"x":{"field":"x"},"y":{"field":"y"}},"id":"1040","type":"Line"},{"attributes":{"data_source":{"id":"1001","type":"ColumnDataSource"},"glyph":{"id":"1035","type":"Line"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1036","type":"Line"},"selection_glyph":null,"view":{"id":"1038","type":"CDSView"}},"id":"1037","type":"GlyphRenderer"}],"root_ids":["1002"]},"title":"Bokeh Application","version":"1.3.4"}}</script><script type="text/javascript">(function(){var fn=function(){Bokeh.safely(function(){(function(root){function embed_document(root){var docs_json=document.getElementById('1128').textContent;var render_items=[{"docid":"7344412d-7bc9-4a59-8502-cdd13ad92044","roots":{"1002":"65c3b379-fc29-489d-aa67-abbad1fcf97f"}}];root.Bokeh.embed.embed_items(docs_json,render_items)}if(root.Bokeh!==undefined){embed_document(root)}else{var attempts=0;var timer=setInterval(function(root){if(root.Bokeh!==undefined){embed_document(root);clearInterval(timer)}attempts++;if(attempts>100){console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");clearInterval(timer)}},10,root)}})(window)})};if(document.readyState!="loading")fn();else document.addEventListener("DOMContentLoaded",fn)})();</script>
$Sigmoid$函数其实是将整个实数轴上的所有实数全部映射到$0 \sim 1$之间，即：$[- \infty, + \infty] \sim [0,1]$，在绝对值很大的时候，会将其映射的值贴近与0或者1。

## $Logestic$ 回归

$Logestic$回归的假设函数如下：
$$
\begin{align}
h_\theta（x）& = g(\theta^T x) \\\\
g(z) & = \frac{1}{1+e^{-z}}
\end{align}
\tag{13}
$$
将其合并为一个公式：
$$
h_\theta = \frac{1}{1+e^{-\theta ^T x}}
\tag{14}
$$
其中$x$是我们的输入，$\theta$为我们要求取的参数。

一个机器学习的模型，实际上是把决策函数限定在某一组条件下，这组限定条件就决定了模型的假设空间。当然，我们还希望这组限定条件简单而合理。而逻辑回归模型所做的假设是：
$$
P( y = 1 | x;\theta) = g(\theta ^Tx) = \frac{1}{1+e^{-\theta ^Tx}}
\tag{15}
$$
这个函数的意思就是在给定$x$和$\theta$的条件下$y=1$的概率。

这里$g(h)$就是我们上面提到的$sigmoid$函数，与之相对应的决策函数为：
$$
y^* = 1, ifP(y=1|x) \gt 0.5
\tag{16}
$$
选择$0.5$作为阈值是一个一般的做法，实际应用时特定的情况可以选择不同阈值，如果对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。

# 梯度下降算法

$$
\Theta^1 = \Theta^0 - \alpha \nabla J (\Theta) \\\\
evaluated \quad at \quad \Theta^0
\tag{17}
$$

此公式的意义是：$J$是关于$\Theta$的一个函数，我们当前所处的位置为$\Theta^0$点，要从这个点走到$J$的最小值点(
此处有可能是极小值二不是最小值)。首先我们先确定前进的方向，也就是梯度的反向，然后走一段距离的步长，也就是$\alpha$，走完这个段步长，就到达了$\Theta^1$这个点！

# 损失函数的选择

对于训练样本来说，我们选择了一条曲线：
$$
\hat{y}_i = \theta_0 + \theta_1 x
\tag{18}
$$
作为其拟合曲线。

我们为其构造了一个损失函数：
$$
C = \sum_{i=1}^n (y_i - \hat{y}_i)^2
\tag{19}
$$
表示每个训练数据点$（x_i, y_i）$到拟合直线$\hat{y_i} = \theta_0 + \theta_1
x$的竖直距离的平方和，通过最小化这个损失函数来求得拟合直线的最佳参数$\mathbb{\theta}$，实际上就是求损失函数$C$在取得最小值情况下$\mathbb{\theta}$的值。
**那么损失函数为什么要用平方差形式呢**，而不是绝对值形式，一次方，三次方，或四次方形式？

简单的说，是因为使用平方形式的时候，使用的是**“最小二乘法”**
的思想，这里的“二乘”指的是用平方来度量观测点与估计点的距离（远近），“最小”指的是参数值要保证各个观测点与估计点的距离的平方和达到最小。

我们设观测输出与预估数据之间的误差为：

$$
{\varepsilon _i} = {y_i} - {\widehat y_i}
\tag{20}
$$

我们通常认为 $\varepsilon$ 服从正态分布，即：
$$
f(\varepsilon _i;u,\sigma ^2) = \frac{1}{\sigma \sqrt {2\pi } }\bullet \exp
\left [ - \frac{(\varepsilon _i - u)^2}{2{\sigma ^2}} \right ]
\tag{21}
$$

我们求的参数$\varepsilon$的极大似然估计$(\mu, \sigma^2)$，即是说，在某个$(\mu, \sigma^2)
$下，使得服从正态分布的$\varepsilon$取得现有样本$\varepsilon$的概率最大。那么根据极大似然估计函数的定义，令：

$$
L(\mu,\sigma^2)=\prod_{i=1}^n \frac{1}{\sqrt{2 \pi}\sigma} \bullet \exp{(-\frac{(\varepsilon_i - \mu)^2}{2 \sigma^2})}
\tag{22}
$$

取对数似然函数：
$$
\log L(\mu, \sigma^2) = -\frac{n}{2} \log \sigma^2 - \frac{n}{2} \log 2 \pi - \frac{\sum_{i=1}^n (\varepsilon_i - \mu)
^2}{2 \sigma^2}
\tag{23}
$$

分别求$(\mu, \sigma^2)$的偏导数，然后置$0$，最后求得参数$(\mu, \sigma^2)$的极大似然估计为：

$$
\mu = \frac{1}{n} \sum_{i=1}{n} \varepsilon_i
\tag{24}
$$

$$
\sigma ^ 2 = \frac{1}{n} \sum_{i=1}^n (\varepsilon_i - \mu) ^ 2
\tag{25}
$$

我们在线性回归中要求得最佳拟合直线$\hat{y_i} = \theta_0 + \theta _ 1
x$，实质上是求预估值$\hat{y_i}$与观测值$y_i$之间的误差$\varepsilon$最小（最好是没有误差）的情况下$\theta$的值。而前面提到过，$\varepsilon$是服从参数$(
\mu, \sigma^2)$的正态分布，那最好是均值$\mu$和方差$\sigma$趋近于$0$或越小越好。即:

$$
\mu = \frac{1}{n} \sum_{i=1}^n \varepsilon_i = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i) \to 0 (越小越好)
\tag{26})
$$

$$
\sigma ^2 = \frac{1}{n} \sum_{i = 1}^n (\varepsilon_i - \mu)^2 = \frac{1}{n} \sum_{i=1}^n (y_i - \widehat y_i - \mu)^2
\approx \frac{1}{n} \sum _{i = 1}^n (y_i - \widehat{y_i})^2
\tag{27}
$$
而这与最前面构建的平方形式损失函数本质上是等价的。
