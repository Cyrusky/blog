---
title: SVD的实现和意义
tags:
  - 数学
categories:
  - AI
  - Mathematics
toc: true
abbrlink: 60ffb787
date: 2020-04-10T09:43:48.000Z
cover: /assets/images/20200410135631.webp
thumbnail: /assets/thumbnail/20200410135631.webp
---

# SVD 概念的复习

对于任意的矩阵$A$，总是可以得到如下的分解:

$$
A = U_m \Sigma_{m \times n} V_n^T \tag{1}
$$

这样的分解被称为奇异值分解（SVD， Singular Value Decomposition），其中$U$为$m$阶方阵（酉矩阵）, $V$为$n$阶方阵（酉矩阵），
$\Sigma$是形状为$m \times n$的非负实数对角矩阵，其中存放的就是我们的奇异值。

<!-- more -->

> **酉矩阵:**
>
> 如果$U$满足： $U^\dagger U = UU^\dagger = I$，则称 U 为一个酉矩阵。
>
> 其中：
>
> $U^\dagger$为$U$的**共轭转置**
>
（共轭之后转置，共轭的概念就是负数共轭。也就是$U^\dagger$在转置以后，其中的每一个元素和$U$中对应位置的元素实部相同，虚部为相反数）。根据上面的描述，如果$U$为实矩阵，则$U^T =
> U^\dagger$

## 举个例子吧

$$
M = \left [
\begin{matrix}
1 & 0&0&0&2 \\\\
0& 0& 3& 0& 0 \\\\
0& 0& 0& 0& 0 \\\\
0& 4& 0& 0& 0
\end{matrix}
\right ]
$$

则$M$的奇异值分解结果为：

$$
U = \left [
\begin{matrix}
0& 0& 1 &0 \\\\
0 &1& 0 &0 \\\\
0 &0& 0 &-1 \\\\
1 &0& 0 &0
\end{matrix}
\right ] ,
\Sigma = \left [
\begin{matrix}
4& 0& 0 &0 &0 \\\\
0 &3& 0 &0 &0\\\\
0 &0& \sqrt{5} &0 & 0\\\\
0 &0& 0 &0 & 0
\end{matrix}
\right ] ,
V^T = \left [
\begin{matrix}
0& 1& 0 &0 & 0 \\\\
0 &0& 1 &0 & 0 \\\\
\sqrt{0.2} &0& 0 &0 & \sqrt{0.8} \\\\
0 &0& 0 &1 & 0 \\\\
\sqrt{0.8} &0& 0 &0 & -\sqrt{0.2}
\end{matrix}
\right ]
$$

## 实现程序

```python
from numpy.linalg import svd
import numpy as np
arr = np.array([[1,0,0,0,2],
                [0,0,3,0,0],
                [0,0,0,0,0],
                [0,4,0,0,0]])
svd(arr)
# (array([[ 0.,  0.,  1.,  0.],
#         [ 0.,  1.,  0.,  0.],
#         [ 0.,  0.,  0., -1.],
#         [ 1.,  0.,  0.,  0.]]),
#  array([4.        , 3.        , 2.23606798, 0.        ]),
#  array([[-0.        ,  1.        ,  0.        , -0.        ,  0.        ],
#         [-0.        ,  0.        ,  1.        , -0.        ,  0.        ],
#         [ 0.4472136 ,  0.        ,  0.        ,  0.        ,  0.89442719],
#         [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],
#         [-0.89442719,  0.        ,  0.        ,  0.        ,  0.4472136 ]]))
```

# 奇异值的几何意义

我们都知道，矩阵的乘法其实是一个坐标的变换过程，这个变换过程包括旋转、拉伸等。

而 SVD
中的$\sigma$是一个有奇异值组成的对角矩阵，因为只是对角线上有非零值，所以，右乘奇异值对角阵的作用相当于将原来的矩阵在各个维度上进行了缩放。照这个思路来考虑的话，我们拿到的所有的数据其实大部分都可以通过各种简单的矩阵进行乘法和各种变换得到。

其实奇异值就是这个作用，就是将我们的数据还原成最基础的空间变幻，而其中的奇异值真是我们变换时的系数。

# 奇异值在数据去噪中的使用

具体可以参考我的另一篇文章：

[奇异值分解的原理与使用:https://www.borgor.cn/2019-09-20/592f7ae4.html](/2019-09-20/592f7ae4.html)

对于某一个图像来说，每一个像素点在灰度的情况下都是一个值域在 0\~255 之间的数值，如果是 RGB 或者 RGBA
的格式下，这个像素点会有多个通道（维度），但是值都是在 0\~255 之间。

我们可以对图像进行奇异值分解，保留部分的奇异值后，我们可以看得出来，图像并不会和奇异值的缺失成线性关系，这种特性就可以用到数据的噪声过滤上。

> 前段时间，有人问过我一个问题，因为我在上面的文章中得出了一个结论，就是对于卡通的图片来说，使用 SVD
> 进行过滤和数据压缩的时候可以保留更多的细节，而对于照片来说，这个奇异值保留的百分比阈值就会高很多。为什么会这个样子？
>
后来经过这篇文章的总结，我们可以得出，现实的照片中，所谓的“噪点”或者说“噪声数据”会很多。奇异值会过滤掉很多噪声，也就是说，现实的照片中，会保留更多的细节，我们经过奇异值过滤后，会过滤掉很多细节，而我们在欣赏照片的时候，有时恰恰是因为这些细节，才会觉得很真实，奇异值却过滤掉了这些细节。
